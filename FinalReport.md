# Metodolog√≠a √Ågil y Estrategia de Branching

##  Metodolog√≠a √Ågil

Para el desarrollo del proyecto se implement√≥ la metodolog√≠a √°gil **Scrum**, utilizando **Jira** como sistema de gesti√≥n de proyectos. Esto nos permiti√≥ organizar el trabajo en sprints, gestionar historias de usuario, asignar tareas y dar seguimiento al avance del equipo.

### Herramienta de Gesti√≥n
- **Jira**: Utilizada para la planificaci√≥n, seguimiento y documentaci√≥n de los sprints, historias de usuario y criterios de aceptaci√≥n.

![tableroJira](images/jira2.png)


##  Estrategia de Branching

Se defini√≥ y document√≥ una estrategia de branching basada en **GitFlow**, adaptada a las necesidades del equipo y del proyecto. Los principales branches utilizados fueron:

- **main**: Rama principal, contiene el c√≥digo estable y listo para producci√≥n.
- **dev**: Rama de desarrollo, donde se integran las nuevas funcionalidades antes de pasar a stage.
- **stage**: Rama de pre-producci√≥n, utilizada para pruebas integradas antes de pasar a producci√≥n.


![branch](images/branch.png)

El flujo de trabajo es el siguiente:
1. Las nuevas funcionalidades y correcciones se desarrollan en ramas feature/ o fix/ a partir de dev.
2. Una vez completadas y revisadas, se integran a dev.
3. Al finalizar un sprint, los cambios de dev se integran en stage para pruebas integradas.
4. Finalmente, tras la validaci√≥n en stage, los cambios se integran en main para su despliegue en producci√≥n.

##  Gesti√≥n de Sprints e Historias de Usuario

Se realizaron **dos sprints completos** durante el desarrollo del proyecto, documentando historias de usuario, criterios de aceptaci√≥n y asignaciones en Jira.

### Sprints Realizados

- **Sprint 1**: Enfocado en la infraestructura, pruebas, monitoreo y CI/CD.
- **Sprint 2**: Enfocado en gesti√≥n de cambios, patrones de dise√±o, seguridad, documentaci√≥n y operaciones.

### Historias de Usuario 


![hus](images/jira1.png)


## Sprint 1

| HU Principal                                  | Subtareas (Resumen)                                                                                                                                    |
| --------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **Infraestructura como C√≥digo con Terraform** | - HU-001: Configuraci√≥n Multi-ambiente con Terraform  <br> - HU-002: Backend Remoto para Estado de Terraform                                           |
| **CI/CD Avanzado**                            | - HU-005: An√°lisis Est√°tico Avanzado con SonarQube <br> - HU-006: Escaneo de Vulnerabilidades con Trivy <br> - HU-007: Versionado Sem√°ntico Autom√°tico |
| **Observabilidad y Monitoreo**                | - HU-008: Stack de Monitoreo con Prometheus y Grafana <br> - HU-009: Gesti√≥n de Logs con ELK Stack <br> - HU-010: Tracing Distribuido                  |
| **Pruebas Avanzadas**                         | - HU-011: Pruebas de Seguridad Automatizadas                                                                                                           |

## Sprint 2

| HU Principal                     | Subtareas (Resumen)                                                                                       |
| -------------------------------- | --------------------------------------------------------------------------------------------------------- |
| **Patrones de Dise√±o Avanzados** | - HU-003: Implementaci√≥n de Patr√≥n Circuit Breaker <br> - HU-004: Configuraci√≥n Externa y Feature Toggles |
| **Change Management**            | - HU-012: Sistema de Change Management                                                                    |
| **Seguridad Avanzada**           | - HU-013: Gesti√≥n Segura de Secretos <br> - HU-014: RBAC y Seguridad de Accesos                           |
| **Documentaci√≥n y Operaciones**  | - HU-015: Manual de Operaciones y Documentaci√≥n                                     |


![husfin](images/jira3.png)

![husfin2](images/jira4.png)


### Criterios de Aceptaci√≥n

Cada historia de usuario en Jira cuenta con criterios de aceptaci√≥n claros y medibles, asegurando que el entregable cumple con los requisitos funcionales y de calidad definidos por el equipo.



![criterios](images/criterios.png)


---

**Resumen:** 
Se implement√≥ Scrum con Jira, se documentaron y gestionaron historias de usuario y sprints, y se utiliz√≥ una estrategia de branching basada en GitFlow con ramas main, dev y stage, cumpliendo con las mejores pr√°cticas de desarrollo √°gil y control de versiones.



## Diagrama de infraestructura

![diagramafinal](images/diagramafinal.png)

##  Cliente y Entrada al Sistema
- **Client:** Los usuarios o sistemas externos interact√∫an con la plataforma a trav√©s de un cliente (navegador, app, etc.).
- **Application Load Balancer:** Todas las peticiones entrantes pasan por un balanceador de carga, que distribuye el tr√°fico de manera eficiente y asegura alta disponibilidad.

## Ciclo DevOps y Despliegue
- **Jenkins Pipeline:** Automatiza la integraci√≥n y entrega continua (CI/CD), construyendo, testeando y desplegando los microservicios.
- **Docker Hub:** Almacena las im√°genes de los microservicios que ser√°n desplegadas en el cl√∫ster de Kubernetes.

## Orquestaci√≥n y Ejecuci√≥n
- **Google Kubernetes Engine (GKE):** Es la plataforma de orquestaci√≥n de contenedores donde se ejecutan todos los microservicios y componentes del sistema.

## Arquitectura de Microservicios
- **API Gateway:** Punto de entrada √∫nico para todas las peticiones internas y externas, gestionando el enrutamiento, autenticaci√≥n y balanceo de carga hacia los microservicios.
- **Service Discovery:** Permite que los microservicios se registren y descubran din√°micamente, facilitando la escalabilidad y resiliencia.
- **Proxy Client:** Abstrae la comunicaci√≥n entre microservicios, gestionando detalles como reintentos y circuit breakers.
- **Circuit Breaker:** Protege el sistema ante fallos, evitando que errores en un servicio afecten a los dem√°s.
- **Zipkin:** Proporciona trazabilidad distribuida, permitiendo rastrear el flujo de las peticiones entre los servicios.

### Microservicios Principales
- **User-Service, Product-Service, Order-Service, Payment-Service:** Cada uno implementa una funcionalidad de negocio espec√≠fica y se comunica con los dem√°s a trav√©s del API Gateway y el Proxy Client.

## Monitoreo y Observabilidad
- **Prometheus:** Recopila m√©tricas de los microservicios y la infraestructura.
- **Grafana:** Visualiza las m√©tricas recolectadas y permite crear dashboards personalizados.
- **Alerts:** Grafana puede generar alertas autom√°ticas ante eventos cr√≠ticos o anomal√≠as detectadas en el sistema.

##  Logs y Trazabilidad
- **Elasticsearch, Logstash, Kibana (ELK Stack):**
  - **Logstash:** Recolecta y procesa logs de los microservicios.
  - **Elasticsearch:** Almacena y permite b√∫squedas r√°pidas sobre los logs.
  - **Kibana:** Visualiza los logs y facilita el an√°lisis y monitoreo.

##  Mensajer√≠a y Procesamiento As√≠ncrono
- **Kafka:** Permite la comunicaci√≥n as√≠ncrona y desacoplada entre microservicios, facilitando la escalabilidad y el procesamiento de eventos en tiempo real.


 Ambientes Definidos

El ciclo de vida del software se gestiona a trav√©s de tres ambientes principales:

- **dev:** Espacio seguro para experimentaci√≥n y desarrollo individual.
- **stage:** Entorno de integraci√≥n y pruebas end-to-end, simula condiciones de producci√≥n.
- **master (producci√≥n):** Entorno estable y seguro, donde se ejecuta la versi√≥n aprobada del sistema.

![cover](images/stages.jpg)



Cada ambiente cuenta con configuraci√≥n propia y pipelines de CI/CD dedicados, permitiendo despliegues independientes y controlados.


## Estructura del proyecto

```
proyecto-infra/
‚îú‚îÄ‚îÄ main.tf                  # Configuraci√≥n principal - orquesta m√≥dulos
‚îú‚îÄ‚îÄ variables.tf             # Variables globales del proyecto
‚îú‚îÄ‚îÄ providers.tf             # Configuraci√≥n del provider de Google Cloud
‚îú‚îÄ‚îÄ backend.tf               # Estado remoto en Google Cloud Storage
‚îú‚îÄ‚îÄ outputs.tf               # Outputs principales del proyecto
‚îú‚îÄ‚îÄ terraform.tfvars         # Variables por defecto
‚îú‚îÄ‚îÄ versions.tf              # Versiones de Terraform y providers
‚îÇ
‚îú‚îÄ‚îÄ environments/            # Configuraciones espec√≠ficas por ambiente
‚îÇ   ‚îú‚îÄ‚îÄ dev/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ backend.tf           # Backend espec√≠fico para desarrollo
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ terraform.tfvars     # Variables para ambiente de desarrollo
‚îÇ   ‚îú‚îÄ‚îÄ stage/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ backend.tf           # Backend espec√≠fico para staging
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ terraform.tfvars     # Variables para ambiente de staging
‚îÇ   ‚îî‚îÄ‚îÄ prod/
‚îÇ       ‚îú‚îÄ‚îÄ backend.tf           # Backend espec√≠fico para producci√≥n
‚îÇ       ‚îî‚îÄ‚îÄ terraform.tfvars     # Variables para ambiente de producci√≥n
‚îÇ
‚îî‚îÄ‚îÄ modules/                   # M√≥dulos reutilizables
    ‚îú‚îÄ‚îÄ vpc/                   # M√≥dulo de red VPC
    ‚îÇ   ‚îú‚îÄ‚îÄ main.tf                # Recursos de red (VPC + Subnetwork)
    ‚îÇ   ‚îú‚îÄ‚îÄ variables.tf           # Variables del m√≥dulo VPC
    ‚îÇ   ‚îî‚îÄ‚îÄ outputs.tf             # Outputs del m√≥dulo VPC
    ‚îú‚îÄ‚îÄ gke/                   # M√≥dulo de Kubernetes
    ‚îÇ   ‚îú‚îÄ‚îÄ main.tf                # Recursos GKE (Cluster + Node Pool)
    ‚îÇ   ‚îú‚îÄ‚îÄ variables.tf           # Variables del m√≥dulo GKE
    ‚îÇ   ‚îî‚îÄ‚îÄ outputs.tf             # Outputs del m√≥dulo GKE
    ‚îú‚îÄ‚îÄ artifact-registry/      # M√≥dulo de Artifact Registry
    ‚îÇ   ‚îú‚îÄ‚îÄ main.tf                # Recursos de Artifact Registry
    ‚îÇ   ‚îú‚îÄ‚îÄ variables.tf           # Variables del m√≥dulo Artifact Registry
    ‚îÇ   ‚îî‚îÄ‚îÄ outputs.tf             # Outputs del m√≥dulo Artifact Registry
    ‚îî‚îÄ‚îÄ monitoring/             # M√≥dulo de Monitoring
        ‚îú‚îÄ‚îÄ main.tf                  # Recursos de Monitoring (alertas, dashboards, etc.)
        ‚îú‚îÄ‚îÄ variables.tf             # Variables del m√≥dulo Monitoring
        ‚îî‚îÄ‚îÄ outputs.tf               # Outputs del m√≥dulo Monitoring

    
```

## Patrones de Dise√±o en la Arquitectura de Microservicios

### Patrones de Dise√±o Identificados en la Arquitectura Existente

###  Microservicios

La arquitectura est√° basada en microservicios, donde cada funcionalidad principal (usuario, producto, pago, etc.) es un servicio independiente, desplegado y escalado de forma aut√≥noma.
 
- Servicios como `user-service`, `product-service`, `payment-service`, etc., cada uno con su propio Dockerfile y despliegue.
- Uso de un `api-gateway` y `service-discovery` (Eureka).

###  Service Discovery 

Se utiliza un servicio de descubrimiento (Eureka) para que los microservicios puedan encontrarse y comunicarse din√°micamente sin necesidad de conocer las direcciones de los dem√°s de antemano.

- Despliegue de `service-discovery` (Eureka).
- Variables de entorno como `EUREKA_CLIENT_SERVICE_URL_DEFAULTZONE` en los contenedores de los microservicios.

###  Externalized Configuration 

La configuraci√≥n de los microservicios se externaliza usando un servidor de configuraci√≥n centralizado (`cloud-config`), permitiendo cambiar configuraciones sin necesidad de reconstruir las im√°genes.

- Despliegue de `cloud-config`.
- Uso de variables como `SPRING_CONFIG_IMPORT=optional:configserver:http://cloud-config-container:9296`.

###  Centralized Logging & Tracing

Se utiliza Zipkin para trazabilidad distribuida, permitiendo rastrear peticiones a trav√©s de los microservicios.
 
- Despliegue de `zipkin`.
- Variables de entorno como `SPRING_ZIPKIN_BASE_URL`.


## Patrones de Dise√±o Implementados

A continuaci√≥n se documentan los patrones de dise√±o implementados en la arquitectura del proyecto, junto con su prop√≥sito, beneficios y un fragmento de c√≥digo representativo de cada uno.



###  Circuit Breaker 

**Prop√≥sito:**  
El patr√≥n Circuit Breaker protege a los microservicios de fallos en cascada cuando una dependencia est√° fallando o responde lentamente. Si detecta varios fallos consecutivos, "abre el circuito" y deja de intentar la operaci√≥n durante un tiempo, devolviendo un error inmediato.

**Beneficios:**
- Previene la sobrecarga de servicios fallando repetidamente.
- Mejora la resiliencia y estabilidad del sistema.
- Permite una recuperaci√≥n m√°s r√°pida y controlada tras un fallo.

**Implementaci√≥n (usando Resilience4j):**
```java
@CircuitBreaker(name = "userService", fallbackMethod = "fallbackGetUser")
public UserDto getUserById(Integer userId) {
    return restTemplate.getForObject("http://USER-SERVICE/api/users/" + userId, UserDto.class);
}

public UserDto fallbackGetUser(Integer userId, Throwable t) {
    // L√≥gica alternativa cuando el circuito est√° abierto o falla la llamada
    return new UserDto(); // o retorna un mensaje de error personalizado
}
```

![cover](images/test1.png)


---

### Feature Toggle

**Prop√≥sito:**  
Permite activar o desactivar funcionalidades del sistema en tiempo real, sin necesidad de desplegar una nueva versi√≥n, mediante configuraci√≥n externa.

**Beneficios:**
- Permite despliegues seguros y pruebas A/B.
- Reduce riesgos al habilitar nuevas funcionalidades de forma controlada.
- Mejora la flexibilidad operativa.

**Implementaci√≥n (usando configuraci√≥n externa):**
```java
@Value("${feature.toggle.newProductFeature:false}")
private boolean newProductFeatureEnabled;

@GetMapping("/new-feature")
public ResponseEntity<String> newFeatureEndpoint() {
    if (!newProductFeatureEnabled) {
        return ResponseEntity.status(HttpStatus.NOT_IMPLEMENTED)
            .body("Funcionalidad no disponible");
    }
    // L√≥gica de la nueva funcionalidad
    return ResponseEntity.ok("Nueva funcionalidad activa");
}
```
> El valor de `feature.toggle.newProductFeature` se puede cambiar en el servidor de configuraci√≥n (`cloud-config`) y recargar din√°micamente.

![cover](images/test2.png)


---

###Retry 

**Prop√≥sito:**  
Permite que los microservicios reintenten autom√°ticamente una operaci√≥n que ha fallado temporalmente antes de devolver un error.

**Beneficios:**
- Mejora la tolerancia a fallos transitorios.
- Reduce la cantidad de errores visibles para el usuario final.
- Aumenta la robustez y confiabilidad de las operaciones cr√≠ticas.

**Implementaci√≥n (Spring Retry):**
```java
@Retryable(
    value = { ProductNotFoundException.class },
    maxAttempts = 3,
    backoff = @Backoff(delay = 1000)
)
public ProductDto findById(final Integer productId) {
    log.info("*** ProductDto, service; fetch product by id *");
    return this.productRepository.findById(productId)
        .map(ProductMappingHelper::map)
        .orElseThrow(() -> new ProductNotFoundException(
            String.format("Product with id: %d not found", productId)));
}
```
> Si la b√∫squeda falla, el m√©todo se reintentar√° hasta 3 veces antes de lanzar la excepci√≥n.

![cover](images/test3.png)


## CI/CD Avanzado

###  An√°lisis Est√°tico de C√≥digo con SonarQube

Se integr√≥ SonarQube en la pipeline para realizar an√°lisis est√°tico de c√≥digo en cada build. El an√°lisis se ejecuta autom√°ticamente y la pipeline puede fallar si no se cumplen los umbrales de calidad.

**Fragmento de Jenkinsfile:**
```groovy
 stage('Run SonarQube Analysis') {
     steps {
         withSonarQubeEnv(credentialsId: 'access_sonarqube', installationName: 'sonarqubesecae') {
             bat "${scannerHome}/bin/sonar-scanner " +
                 "-Dsonar.projectKey=${service} " +
                 "-Dsonar.projectName=${service} " +
                 '-Dsonar.sources=src ' +
                 '-Dsonar.java.binaries=target/classes'
         }
     }
 }
```
> Este stage ejecuta el an√°lisis de SonarQube para cada microservicio, usando el scanner oficial y variables de entorno seguras.

![cover](images/sonar1.jpg)
![cover](images/sonar2.jpg)


#### **Interpretaci√≥n de los resultados de SonarQube**

Las im√°genes muestran el dashboard de SonarQube tras los an√°lisis autom√°ticos de los microservicios.  
- **Todos los microservicios analizados han pasado el Quality Gate** (indicador verde "Passed"), lo que significa que cumplen con los umbrales de calidad definidos para seguridad, mantenibilidad y fiabilidad.
- **No se detectaron issues de seguridad, fiabilidad ni mantenibilidad** (todos los indicadores en "A").
- **Cobertura de c√≥digo y duplicaci√≥n:** En los ejemplos mostrados, la cobertura de tests es 0% en algunos servicios, lo que indica que no se han instrumentado tests autom√°ticos o no se han reportado correctamente. Sin embargo, no hay duplicaci√≥n de c√≥digo.
- **Resumen:** El c√≥digo es seguro, confiable y mantenible seg√∫n SonarQube, pero se recomienda mejorar la cobertura de tests para mayor robustez.

---

## Escaneo de Vulnerabilidades en Contenedores con Trivy

Se implement√≥ un stage dedicado para escanear las im√°genes Docker de todos los microservicios usando Trivy. Si se detectan vulnerabilidades cr√≠ticas, la pipeline puede detenerse.

**Fragmento de Jenkinsfile:**
```groovy
stage('Trivy Vulnerability Scan & Report') {
    when { branch 'stage' }
    environment {
        TRIVY_PATH = 'C:/ProgramData/chocolatey/bin'
    }
    steps {
        script {
            env.PATH = "${TRIVY_PATH};${env.PATH}"
            def services = [ ... ]
            bat """
            if not exist trivy-reports (
                mkdir trivy-reports
            )
            """
            services.each { service ->
                def reportPath = "trivy-reports\\${service}.html"
                echo "üîç Escaneando imagen ${IMAGE_TAG} con Trivy para ${service}..."
                bat """
                trivy image --format template ^
                    --template "@C:/ProgramData/chocolatey/lib/trivy/tools/contrib/html.tpl" ^
                    --severity HIGH,CRITICAL ^
                    -o ${reportPath} ^
                    ${DOCKERHUB_USER}/${service}:${IMAGE_TAG}
                """
            }
            publishHTML(target: [
                allowMissing: true,
                alwaysLinkToLastBuild: true,
                keepAll: true,
                reportDir: 'trivy-reports',
                reportFiles: '*.html',
                reportName: 'Trivy Scan Report'
            ])
        }
    }
}
```
> Este stage escanea todas las im√°genes y publica un reporte HTML con los resultados de Trivy.

![cover](images/trivi1.jpg)

#### **resultados de Trivy**

La imagen muestra un reporte generado por Trivy para la imagen Docker de `api-gateway`.  
- **Se detectan varias vulnerabilidades cr√≠ticas y altas** en paquetes del sistema base (por ejemplo, `curl` y `bash`).
- **Columnas clave:**  
  - **Severity:** Indica el nivel de criticidad (CRITICAL/HIGH).
  - **Installed Version / Fixed Version:** Muestra la versi√≥n instalada y la versi√≥n donde el problema est√° corregido.
  - **Links:** Proporciona enlaces a los reportes oficiales de cada vulnerabilidad (CVE).
- **Acci√≥n recomendada:**  
  - Actualizar la imagen base a una versi√≥n m√°s reciente donde las vulnerabilidades est√©n corregidas.
  - Si no es posible, evaluar el riesgo y aplicar mitigaciones (por ejemplo, restringir el uso de los paquetes afectados).

- **Resumen:** El escaneo de Trivy es fundamental para asegurar que las im√°genes Docker no contienen vulnerabilidades conocidas. El pipeline puede configurarse para fallar autom√°ticamente si se detectan vulnerabilidades cr√≠ticas, evitando as√≠ la promoci√≥n de im√°genes inseguras a producci√≥n.

---

##  Notificaciones Autom√°ticas de Fallos

La pipeline est√° configurada para enviar notificaciones autom√°ticas por correo electr√≥nico en caso de fallo en cualquier etapa.

**Fragmento de Jenkinsfile:**
```groovy
post {
    failure {
        echo "‚ùå Fall√≥ pipeline en ${env.BRANCH_NAME}. Ver logs."
        emailext(
            attachLog: true,
            body: '$DEFAULT_CONTENT',
            subject: '$DEFAULT_SUBJECT',
            to: '$DEFAULT_RECIPIENTS',
        )
    }
}
```
> Si la pipeline falla, se env√≠a un correo con el log adjunto a los destinatarios configurados.

---

## 4. Aprobaciones para Despliegues a Producci√≥n

Antes de desplegar a producci√≥n, se requiere una aprobaci√≥n manual desde la interfaz de Jenkins. Adem√°s, se notifica por correo que la build est√° pendiente de aprobaci√≥n.

**Fragmento de Jenkinsfile:**
```groovy
 stage('Waiting approval for deployment') {
     when { branch 'master' }
     steps {
         script {
             emailext(
                 to: '$DEFAULT_RECIPIENTS',
                 subject: "Action Required: Approval Needed for Deploy of Build #${env.BUILD_NUMBER}",
                 body: """\
                 The build #${env.BUILD_NUMBER} for branch *${env.BRANCH_NAME}* has completed and is pending approval for deployment.
                 Please review the changes and approve or abort
                 You can access the build details here:
                 ${env.BUILD_URL}
                 """
             )
             input message: 'Approve deployment to production (kubernetes) ?', ok: 'Deploy'
         }
     }
 }
```
> Este stage env√≠a un correo solicitando aprobaci√≥n y detiene la pipeline hasta que un responsable apruebe el despliegue.

## Notificaciones autom√°ticas para fallos en la pipeline

![notis](images/noti.jpg)
---

## Informe de Cobertura y Calidad de Pruebas

Se muestra qu√© porcentaje del c√≥digo fuente es ejecutado por los tests autom√°ticos. Las m√©tricas principales son:

- **Cobertura de instrucciones:** Porcentaje de l√≠neas de c√≥digo ejecutadas por los tests.
- **Cobertura de ramas:** Porcentaje de bifurcaciones (if, else, switch, etc.) ejecutadas.
- **Cobertura por clases/m√©todos:** Porcentaje de clases y m√©todos ejecutados al menos una vez por los tests.

---

![cover](images/reporte1.jpg)

###  Informe de cobertura: `product-service`

| M√©trica                       | Valor                        |
|-------------------------------|------------------------------|
| Cobertura de instrucciones    | **85%** (2,147 de 2,514)     |
| Cobertura de ramas            | **100%** (276 de 276)        |
| Clases cubiertas              | 15 de 26                     |
| M√©todos cubiertos             | 160 de 218                   |
| Tests fallidos                | 0                            |

**Observaciones:**
- Los paquetes `com.selimhorri.app.dto` y `com.selimhorri.app.exception.payload` tienen menor cobertura (21% y 18% respectivamente).
- Otros paquetes como `resource`, `service.impl`, `helper`, etc., tienen 0% de cobertura, lo que indica que no est√°n siendo probados por los tests.
- La mayor√≠a de los m√©todos y l√≠neas est√°n cubiertos, pero hay √°reas de mejora en DTOs y excepciones.

---

![cover](images/reporte2.jpg)

###  Informe de cobertura: `user-service`

| M√©trica                       | Valor                        |
|-------------------------------|------------------------------|
| Cobertura de instrucciones    | **20%** (3,878 de 4,854)     |
| Cobertura de ramas            | **97%** (494 de 512)         |
| Clases cubiertas              | 30 de 43                     |
| M√©todos cubiertos             | 297 de 395                   |
| Tests fallidos                | 0                            |

**Observaciones:**
- La cobertura es significativamente m√°s baja que en `product-service`.
- Los paquetes `dto` y `resource` tienen coberturas bajas (29% y 6% respectivamente).
- Hay muchos m√©todos y l√≠neas no cubiertas, especialmente en DTOs y helpers.
- Se recomienda aumentar la cobertura en los paquetes cr√≠ticos para mejorar la calidad y detectar errores antes.

---

![cover](images/reporte3.jpg)

### Resultados de los tests

| Paquete                                 | Duraci√≥n | Fallidos | Pasados | Total |
|------------------------------------------|----------|----------|---------|-------|
| com.selimhorri.app.integration          | 16 seg   | 0        | 7       | 7     |
| com.selimhorri.app.unit                  | 3.3 seg  | 0        | 6       | 6     |
| com.selimhorri.app.unit.service          | 4.5 seg  | 0        | 12      | 12    |
| **Total**                               | 2:49 min | **0**    | **25**  | **25**|

Todos los tests existentes pasan correctamente, lo que indica que el c√≥digo cubierto por los tests funciona como se espera. Sin embargo, la baja cobertura en algunos servicios (especialmente en `user-service`) sugiere que hay partes del c√≥digo que no est√°n siendo probadas y podr√≠an contener errores no detectados.

---

### Conclusi√≥n y recomendaciones

- **Cobertura alta (`product-service`):** Es buena (85%), pero a√∫n hay √°reas (DTOs, excepciones) que pueden mejorarse.
- **Cobertura baja (`user-service`):** Es baja (20%), lo que representa un riesgo. Se recomienda crear m√°s tests, especialmente para los paquetes con menor cobertura.
- **Calidad de pruebas:** Todos los tests pasan, pero la calidad general


## Change Management y Planes de Rollback

###  Proceso Formal de Change Management

El proceso de Change Management asegura que todos los cambios en la arquitectura, c√≥digo o infraestructura sean gestionados de manera controlada, minimizando riesgos y garantizando la trazabilidad.

### Fases del Proceso

 **Solicitud de Cambio (RFC - Request for Change)**
   - Todo cambio debe ser propuesto mediante un issue o ticket en el sistema de gesti√≥n de proyectos (por ejemplo, GitHub Issues, Jira).
   - La solicitud debe incluir: descripci√≥n, justificaci√≥n, impacto esperado, riesgos y plan de pruebas.

 **Evaluaci√≥n y Aprobaci√≥n**
   - El equipo de desarrollo y/o arquitecto revisa la solicitud.
   - Se eval√∫an riesgos, dependencias y se prioriza el cambio.
   - Si es aprobado, se asigna a un responsable y se planifica en el sprint correspondiente.

 **Desarrollo y Pruebas**
   - El cambio se implementa en una rama espec√≠fica.
   - Se realizan pruebas unitarias, de integraci√≥n y, si aplica, pruebas de carga.
   - Se documentan los resultados en el pull request.

 **Revisi√≥n y Validaci√≥n**
   - Code review obligatorio por al menos un miembro del equipo.
   - Validaci√≥n en ambiente de staging/pre-producci√≥n.

 **Despliegue Controlado**
   - El cambio se despliega usando pipelines automatizados (CI/CD).
   - Se monitorea el sistema tras el despliegue para detectar posibles incidencias.

 **Documentaci√≥n y Comunicaci√≥n**
   - Se actualizan los documentos t√©cnicos y de usuario.
   - Se comunica el cambio a los stakeholders mediante Release Notes.

 **Cierre**
   - Se cierra la solicitud de cambio y se archiva la documentaci√≥n asociada.


##  Planes de Rollback


El plan de rollback define los pasos a seguir para revertir un despliegue en caso de que se detecten problemas cr√≠ticos tras la liberaci√≥n de una nueva versi√≥n.

### Estrategia General

- **Despliegue Blue/Green o Canary:** Mantener la versi√≥n anterior activa hasta validar la nueva.
- **Backups:** Realizar backups de bases de datos y configuraciones antes de cada despliegue.
- **Automatizaci√≥n:** Usar scripts o pipelines para revertir a la versi√≥n anterior de los servicios y configuraciones.

### Pasos para Rollback

 **Identificaci√≥n del Problema**
   - Monitorear logs y m√©tricas tras el despliegue.
   - Si se detecta un fallo cr√≠tico, notificar al equipo y a los stakeholders.

 **Ejecuci√≥n del Rollback**
   - Revertir el despliegue usando el pipeline de CI/CD (por ejemplo, desplegar la imagen Docker de la versi√≥n anterior).
   - Restaurar backups de base de datos si es necesario.
   - Revertir cambios en la configuraci√≥n desde el servidor de configuraci√≥n centralizado.

 **Validaci√≥n**
   - Verificar que el sistema funciona correctamente con la versi√≥n anterior.
   - Realizar pruebas b√°sicas de smoke testing.

 **Documentaci√≥n**
   - Registrar el incidente, las causas y las acciones tomadas.
   - Actualizar los documentos de lecciones aprendidas.


##  Prometheus: Recolecci√≥n de M√©tricas y Gesti√≥n de Alertas

Prometheus act√∫a como el sistema principal para la recolecci√≥n de m√©tricas de todos los microservicios y del cl√∫ster de Kubernetes.

![prome](images/prome1.jpg)

La imagen muestra la interfaz de consulta de Prometheus, lista para ejecutar expresiones PromQL. Esto indica que Prometheus est√° operativo y listo para consultar las m√©tricas recolectadas de los diferentes **targets** (servicios o componentes monitoreados).

## Reglas de Alertas en Prometheus


![prome](images/prome2.jpg)

![prome](images/prome3.jpg)

Se observa la configuraci√≥n de reglas de alertas cargadas en Prometheus, agrupadas por archivos de configuraci√≥n:

- **alertmanager.rules**: Contiene reglas relacionadas con el propio Alertmanager, como fallos en el env√≠o de alertas (`AlertmanagerFailedToSendAlerts`) o inconsistencias en la configuraci√≥n (`AlertmanagerConfigInconsistent`). La mayor√≠a est√°n **INACTIVAS**, lo cual es un buen indicador de funcionamiento normal.

- **config-reloaders**: Incluye alertas para errores en la recarga de configuraciones, como `ConfigReloaderSidecarErrors`. Esta alerta tambi√©n est√° **INACTIVA**.

- **pods.critical**: Contiene una alerta (`DeploymentDown`) que monitorea el estado de los despliegues de pods. Est√° **INACTIVA**, lo que significa que no hay despliegues ca√≠dos.

La presencia de estas reglas demuestra un monitoreo proactivo de la salud del cl√∫ster y del sistema de alertas.



##  Grafana: Visualizaci√≥n de Dashboards y Estado del Monitoreo

Grafana es la herramienta de visualizaci√≥n que consume las m√©tricas de Prometheus para presentarlas en dashboards intuitivos.

## Dashboard de Prometheus Overview 

![graf](images/grafana1.jpg)
![graf](images/grafana2.jpg)

Proporciona una visi√≥n de la salud del propio Prometheus:

- **Prometheus Stats**: Muestra la instancia (`prometheus-stack-kube-prom-prometheus`) y su versi√≥n (`3.4.1`).
- **Discovery (Target Sync)**: Latencia de sincronizaci√≥n baja (<100ms), indicando buena salud.
- **Targets**: Se est√°n monitoreando alrededor de **300-400 objetivos**.
- **Retrieval (Average Scrape Interval Duration)**: <50ms, lo cual es positivo.
- **Scrape Failures**: No hay fallos significativos.
- **Appended Samples**: Muestra el volumen de datos de monitoreo.

Este dashboard es clave para asegurar que Prometheus funciona √≥ptimamente.

## Dashboards de Kubernetes (Compute Resources)

Visualizaciones clave sobre uso de recursos a nivel de infraestructura.

### Cluster 

![graf](images/grafana3.jpg)

- **CPU Utilisation**: 15.4%
- **CPU Requests Commitment**: 36.2%
- **CPU Limits Commitment**: 264%  
  > Esto indica que los l√≠mites de CPU superan por mucho los recursos disponibles, lo cual puede causar throttling.

- **Memory Utilisation**: 31.5%
- **Memory Requests Commitment**: 13.5%
- **Memory Limits Commitment**: 73.7%

### CPU y Memoria por Namespace

Namespaces observados: `ecommerce`, `kube-system`, `gmp-system`, `logging`, `monitoring`.

El namespace `ecommerce` tiene una carga significativa, y los namespaces del sistema tambi√©n est√°n activos, indicando buen funcionamiento general.

### Nodes/Pods 

![graf](images/grafana4.jpg)

![graf](images/grafana5.jpg)

![graf](images/promepods.jpg)

#### Uso de CPU por Pod

Microservicios monitoreados:
- `api-gateway`, `cloud-config`, `favourite-service`, `order-service`, `payment-service`, `product-service`, `service-discovery`, `user-service`, `zipkin`.

Se observan fluctuaciones normales bajo carga. Algunos picos (como en `favourite-service` y `order-service`) pueden deberse a pruebas o tr√°fico real.

#### Uso de Memoria por Pod

- `api-gateway` y `cloud-config` presentan uso constante.
- Otros servicios muestran mayor variabilidad.

#### CPU Utilisation (from requests / from limits)

- **776% (cl√∫ster)** y **248% (ecommerce)** desde l√≠mites:  
  > Indica throttling severo por sobreuso de CPU m√°s all√° de los l√≠mites asignados.

#### Memory Utilisation (from requests / from limits)

- **3040% (cl√∫ster)** y **1520% (ecommerce)** desde l√≠mites:  
  > Riesgo cr√≠tico de OOMKilled o degradaci√≥n por l√≠mites demasiado bajos. Urge revisar configuraci√≥n de recursos en los manifiestos de Kubernetes.


##  ELK Stack en el Proyecto


**ELK** es un stack de herramientas de c√≥digo abierto compuesto por:

- **Elasticsearch**: Motor de b√∫squeda y an√°lisis de datos.
- **Logstash**: Pipeline para ingesta, transformaci√≥n y env√≠o de logs.
- **Kibana**: Plataforma de visualizaci√≥n de datos.
- **Filebeat** (complementario): Agente ligero para enviar logs a Logstash o Elasticsearch.


### ¬øPara que nos sirve ELK en este proyecto?

- **Centralizaci√≥n de logs**: Todos los logs de los servicios y aplicaciones del cl√∫ster GKE se env√≠an a Elasticsearch.
- **Visualizaci√≥n**: Kibana permite consultar y visualizar los logs en dashboards.
- **Procesamiento**: Logstash puede transformar y enriquecer los logs antes de almacenarlos.
- **Alertas y auditor√≠a**: Permite detectar errores, anomal√≠as y realizar auditor√≠a de eventos.


## Implementaci√≥n

La implementaci√≥n se realiza de forma automatizada en el pipeline de Jenkins, usando Helm charts sobre Kubernetes (GKE). El despliegue ocurre en el namespace `logging`.

### 1. Despliegue Autom√°tico con Jenkins

En el Jenkinsfile, el despliegue de ELK se realiza en la etapa `Deploy ELK Stack`:

```groovy
stage('Deploy ELK Stack') {
    when { branch 'master' }
    steps {
        bat '''
            echo "üìä Deploying ELK Stack (Elasticsearch, Logstash, Kibana) and Filebeat..."

            helm repo add elastic https://helm.elastic.co
            helm repo update

            echo "üì¶ Deploying Elasticsearch..."
            helm upgrade --install elasticsearch elastic/elasticsearch ^
            --namespace logging --create-namespace ^
            -f modules/monitoring/elasticsearch-values.yaml

            echo "‚è≥ Waiting for Elasticsearch to be ready..."
            kubectl wait --for=condition=Ready pod -l app=elasticsearch-master ^
            --namespace logging --timeout=600s

            echo "üì¶ Deploying Logstash..."
            helm upgrade --install logstash elastic/logstash ^
            --namespace logging ^
            -f modules/monitoring/logstash-values.yaml

            echo "üì¶ Deploying Kibana..."
            helm upgrade --install kibana elastic/kibana ^
            --namespace logging ^
            -f modules/monitoring/kibana-values.yaml

            echo "üì¶ Deploying Filebeat..."
            helm upgrade --install filebeat elastic/filebeat ^
            --namespace logging ^
            -f modules/monitoring/filebeat-values.yaml

            echo "‚úÖ ELK Stack and Filebeat deployed successfully!"
        '''
    }
}
```

### 2. Componentes Desplegados

- **Elasticsearch**: Almacena y permite b√∫squedas sobre los logs.
- **Logstash**: Procesa y transforma los logs antes de enviarlos a Elasticsearch.
- **Kibana**: Visualiza los logs y m√©tricas.
- **Filebeat**: Recolecta logs de los pods y los env√≠a a Logstash/Elasticsearch.

### 3. Verificaci√≥n

 verificar que los pods est√°n corriendo con:

```sh
kubectl get pods -n logging
```

Ejemplo de salida:

![elk](images/elk.jpg)

## Acceso y Uso

- **Kibana**: Usualmente se expone como un servicio. Puedes acceder a la interfaz web para visualizar y consultar logs.
- **Elasticsearch**: Puede ser accedido por aplicaciones o herramientas para b√∫squedas avanzadas.
- **Logstash y Filebeat**: Funcionan en segundo plano recolectando y procesando logs.

---

## Archivos de configuraci√≥n

Los valores personalizados para cada componente est√°n en:

- `modules/monitoring/elasticsearch-values.yaml`
- `modules/monitoring/logstash-values.yaml`
- `modules/monitoring/kibana-values.yaml`
- `modules/monitoring/filebeat-values.yaml`


## Alertas para situaciones criticas

Cuando ocurre una situaci√≥n cr√≠tica (por ejemplo, ca√≠da de kube-proxy), se env√≠a autom√°ticamente un correo electr√≥nico al equipo, como se muestra en la siguiente imagen:

![alertas](images/alertas.png)

El correo incluye:
- Nombre y severidad de la alerta.
- Descripci√≥n y resumen del problema.
- Enlace directo a Alertmanager y a la documentaci√≥n de resoluci√≥n (runbook).




## Costos de Infraestructura y Uso de Google Cloud para el Despliegue

### Uso de Google Cloud Platform (GCP)

Para el despliegue de la soluci√≥n, se utiliz√≥ **Google Cloud Platform (GCP)**, aprovechando sus servicios gestionados y escalables para infraestructura de microservicios. El proyecto se gestion√≥ bajo la cuenta de facturaci√≥n de GCP, la cual proporciona cr√©ditos gratuitos iniciales para desarrollo y pruebas, permitiendo experimentar y desplegar sin incurrir en costos inmediatos.

#### Recursos principales utilizados en GCP:

- **Google Kubernetes Engine (GKE):**  
  Se despleg√≥ un cl√∫ster de Kubernetes gestionado, facilitando la orquestaci√≥n, escalabilidad y alta disponibilidad de los microservicios.  

 ![GKE cluster](images/gke1.jpg)


  ![GKE cluster](images/cloud.jpg)

- **Compute Engine:**  
  Provisi√≥n de m√°quinas virtuales para nodos del cl√∫ster y otros servicios auxiliares.

- **Cloud Storage:**  
  Almacenamiento de artefactos, backups y archivos de estado de Terraform.

- **Artifact Registry:**  
  Almacenamiento seguro de im√°genes Docker para los microservicios.

- **Stackdriver (Operations Suite):**  
  Monitoreo, logging y alertas integradas con los servicios desplegados.

- **VPC y Networking:**  
  Configuraci√≥n de redes privadas, balanceadores de carga y reglas de firewall para asegurar la comunicaci√≥n entre servicios y la exposici√≥n controlada hacia el exterior.



## Pods Subidos

![Consumo de cr√©ditos](images/pods.jpg)


### Costos de Infraestructura

#### Cr√©ditos y control de gastos

- El proyecto se benefici√≥ de los **cr√©ditos gratuitos** de GCP, permitiendo consumir recursos sin costo hasta agotar el saldo asignado.
- Se configuraron **alertas de presupuesto** para evitar sobrecostos y monitorear el uso de los cr√©ditos en tiempo real.
- El dashboard de facturaci√≥n de GCP permite visualizar el consumo y estimar los costos mensuales proyectados.

#### Ejemplo de consumo de cr√©ditos

![Consumo de cr√©ditos](images/costos.jpg)

- **Cr√©ditos usados:** $86,403 de $1,235,798 
- **Fecha de vencimiento de cr√©ditos:** 2 de septiembre de 2025

#### Detalle de recursos y costos estimados

- **Cl√∫ster de Kubernetes (GKE):**
  - **Ubicaci√≥n:** us-central1
  - **Cantidad de nodos:** 3
  - **CPU virtuales totales:** 12
  - **Memoria total:** 48 GB
  - **Costo mensual estimado:** $0.00/mes (cubierto por cr√©ditos)
  - **Estado:** 100% en buen estado


- **Otros servicios:**  
  El uso de servicios como Cloud Storage, Artifact Registry y Stackdriver genera costos adicionales, pero estos tambi√©n est√°n cubiertos por los cr√©ditos gratuitos durante la etapa de desarrollo.

---

### Ventajas de usar Google Cloud para el despliegue

- **Escalabilidad autom√°tica:** GKE permite ajustar el n√∫mero de nodos y recursos seg√∫n la demanda.
- **Alta disponibilidad:** Servicios gestionados y balanceadores de carga aseguran la continuidad del servicio.
- **Seguridad:** Integraci√≥n con IAM, redes privadas y control de acceso granular.
- **Monitoreo y alertas integrados:** Stackdriver y Prometheus permiten monitorear el estado de la infraestructura y recibir alertas proactivas.
- **Despliegue automatizado:** Integraci√≥n con pipelines de CI/CD para despliegues continuos y controlados.

---


## Manual de Operaciones B√°sico

Este manual describe los procedimientos esenciales para operar, mantener y monitorear la soluci√≥n de microservicios desplegada en Google Cloud Platform (GCP) usando Kubernetes (GKE), CI/CD, monitoreo y logging centralizado.

---

### Acceso a la Infraestructura

#### Google Cloud Platform (GCP)
- **URL:** [https://console.cloud.google.com/](https://console.cloud.google.com/)
- **Proyecto:** `proyecto-final-ingesoftv`


#### Acceso al cl√∫ster de Kubernetes (GKE)
- Desde la consola de GCP, ir a **Kubernetes Engine > Cl√∫steres**.
- Seleccionar el cl√∫ster `ecommerce-cluster-prod`.
- Para acceso por terminal:
  ```sh
  gcloud container clusters get-credentials ecommerce-cluster-prod --region us-central1
  kubectl get pods -A
  ```



###  Despliegue de Microservicios

#### Despliegue Autom√°tico (CI/CD)
- Los despliegues se realizan autom√°ticamente mediante pipelines de Jenkins.
- Cada push a la rama `dev` o `prod` dispara la pipeline correspondiente.
- El pipeline ejecuta:
  - Build y pruebas autom√°ticas
  - An√°lisis de calidad (SonarQube, Trivy)
  - Despliegue en GKE usando Helm

#### Despliegue Manual
- Para forzar un despliegue manual:
  1. Acceder a Jenkins.
  2. Seleccionar el job del microservicio.
  3. Hacer clic en "Build Now" o "Deploy".



### 3. Monitoreo y Alertas

#### Prometheus y Grafana
- **Prometheus:** Recolecta m√©tricas de los microservicios y del cl√∫ster.
- **Grafana:** Visualiza dashboards de m√©tricas.
- **Acceso a Grafana:**  
  - URL: http://127.0.0.1:9090/query
  - Usuario/contrase√±a

### Alertas
- Las alertas est√°n configuradas en Prometheus y se notifican por correo electr√≥nico ante eventos cr√≠ticos (ca√≠da de pods, uso excesivo de recursos, etc.).



## 4. Centralizaci√≥n de Logs

### ELK Stack (Elasticsearch, Logstash, Kibana, Filebeat)
- **Kibana:** Acceso a dashboards y consultas de logs.
  - URL: http://127.0.0.1:5601/
- **Elasticsearch:** Almacena todos los logs de los microservicios.
- **Filebeat:** Recolecta logs de los pods y los env√≠a a Logstash/Elasticsearch.



## 5. Gesti√≥n de Configuraci√≥n

- La configuraci√≥n de los microservicios se gestiona de forma centralizada mediante `cloud-config`.
- Para actualizar configuraciones:
  1. Modificar el archivo correspondiente en el repositorio de configuraci√≥n.
  2. Hacer commit y push.
  3. Los microservicios recargar√°n la configuraci√≥n autom√°ticamente o tras reinicio.



## 6. Escalado y Mantenimiento

### Escalado de Pods
- Para escalar un microservicio:
  ```sh
  kubectl scale deployment <nombre-deployment> --replicas=<n√∫mero>
  ```

### Actualizaci√≥n de Im√°genes
- Las nuevas versiones se despliegan autom√°ticamente por CI/CD.
- Para forzar una actualizaci√≥n:
  ```sh
  kubectl rollout restart deployment <nombre-deployment>
  ```



## 7. Backup y Recuperaci√≥n

- **Backups autom√°ticos** de bases de datos y configuraciones se realizan peri√≥dicamente (verificar configuraci√≥n en Cloud SQL y Cloud Storage).
- Para restaurar un backup, seguir el procedimiento documentado en la consola de GCP o scripts de recuperaci√≥n.



## 8. Rollback de Despliegues

- Si un despliegue falla, se puede revertir a la versi√≥n anterior desde Jenkins o usando Helm:
  ```sh
  helm rollback <release> <revision>
  ```
- Tambi√©n se puede restaurar una imagen Docker anterior y redeplegar.



## 9. Seguridad y Accesos

- El acceso a la infraestructura est√° restringido mediante IAM de GCP.
- Cada usuario debe tener su propia cuenta y permisos m√≠nimos necesarios.
- Las credenciales sensibles se almacenan en Secret Manager o como Kubernetes Secrets.


